{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Project: Predicting Housing Prices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we will go through the iterative process of specifying, fitting, and analyzing the performance of a  model.  \n",
    "\n",
    "In the first portion of the project, we will guide you through some basic exploratory data analysis (EDA), laying out the thought process that leads to certain modeling decisions. Next, you will be adding a few new features to the dataset, cleaning the data as well in the process. Then, you will specify and fit a linear model to a few features of the housing data to predict housing prices. Finally, we will analyze the error of the model and brainstorm ways to improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f68729731e7fe39d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# The Data\n",
    "\n",
    "The dataset you’ll be working with comes from the Cook County Assessor’s Office (CCAO) in Illinois, a government institution that determines property taxes across most of Chicago’s metropolitan area and its nearby suburbs. In the United States, all property owners are required to pay property taxes, which are then used to fund public services including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models that consider multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "The CCAO dataset consists of over 500 thousand records describing houses sold in Cook County in recent years (new records are still coming in every week!). The data set we will be working with has 61 features in total. An explanation of each variable can be found in the included `codebook.txt` file. Some of the columns have been filtered out to ensure this assignment doesn't become overly long when dealing with data cleaning and formatting.\n",
    "\n",
    "The data are split into training and test sets with 204792 and 68264 observations, respectively.\n",
    "\n",
    "Let's first extract the data from the `cook_county_data.zip`. Notice we didn't leave the `csv` files directly in the directory because they take up too much space without some prior compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('cook_county_data.zip') as item:\n",
    "    item.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"cook_county_train.csv\", index_col='Unnamed: 0')\n",
    "test_data = pd.read_csv(\"cook_county_test.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 206032 observations and 68 features in training data\n",
    "assert training_data.shape == (204792, 62)\n",
    "# 68678 observations and 68 features in test data\n",
    "assert test_data.shape == (68264, 61)\n",
    "# Sale Price is provided in the training data\n",
    "assert 'Sale Price' in training_data.columns.values\n",
    "# Sale Price is hidden in the test data\n",
    "assert 'Sale Price' not in test_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The next order of business is getting a feel for the variables in our data.  The Cook County data set contains information that typical homebuyers would want to know.  A more detailed description of each variable is included in `codebook.txt` (in the same directory as this notebook).  **You should take some time to familiarize yourself with the codebook before moving forward.**\n",
    "\n",
    "Let's take a quick look at all the current columns in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This property, sold on 02/18/2016, is a one-story houeshold located at 11415 S PRAIRIE AVE.It has a total of 7 rooms, 3 of which are bedrooms, and 1.0 of which are bathrooms.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIN</th>\n",
       "      <th>Property Class</th>\n",
       "      <th>Neighborhood Code</th>\n",
       "      <th>Land Square Feet</th>\n",
       "      <th>Town Code</th>\n",
       "      <th>Apartments</th>\n",
       "      <th>Wall Material</th>\n",
       "      <th>Roof Material</th>\n",
       "      <th>Basement</th>\n",
       "      <th>Basement Finish</th>\n",
       "      <th>...</th>\n",
       "      <th>Sale Month of Year</th>\n",
       "      <th>Sale Half of Year</th>\n",
       "      <th>Most Recent Sale</th>\n",
       "      <th>Age Decade</th>\n",
       "      <th>Pure Market Filter</th>\n",
       "      <th>Garage Indicator</th>\n",
       "      <th>Neigborhood Code (mapping)</th>\n",
       "      <th>Town and Neighborhood</th>\n",
       "      <th>Description</th>\n",
       "      <th>Lot Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17294100610000</td>\n",
       "      <td>203</td>\n",
       "      <td>50</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>7650</td>\n",
       "      <td>This property, sold on 09/14/2015, is a one-st...</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13272240180000</td>\n",
       "      <td>202</td>\n",
       "      <td>120</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>71120</td>\n",
       "      <td>This property, sold on 05/23/2018, is a one-st...</td>\n",
       "      <td>3780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25221150230000</td>\n",
       "      <td>202</td>\n",
       "      <td>210</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210</td>\n",
       "      <td>70210</td>\n",
       "      <td>This property, sold on 02/18/2016, is a one-st...</td>\n",
       "      <td>4375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10251130030000</td>\n",
       "      <td>203</td>\n",
       "      <td>220</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>220</td>\n",
       "      <td>17220</td>\n",
       "      <td>This property, sold on 07/23/2013, is a one-st...</td>\n",
       "      <td>4375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31361040550000</td>\n",
       "      <td>202</td>\n",
       "      <td>120</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>32120</td>\n",
       "      <td>This property, sold on 06/10/2016, is a one-st...</td>\n",
       "      <td>8400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204787</th>\n",
       "      <td>25163010260000</td>\n",
       "      <td>202</td>\n",
       "      <td>321</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>321</td>\n",
       "      <td>72321</td>\n",
       "      <td>This property, sold on 07/23/2014, is a one-st...</td>\n",
       "      <td>4375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204788</th>\n",
       "      <td>5063010090000</td>\n",
       "      <td>204</td>\n",
       "      <td>21</td>\n",
       "      <td>16509.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2321</td>\n",
       "      <td>This property, sold on 03/27/2019, is a one-st...</td>\n",
       "      <td>16509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204789</th>\n",
       "      <td>16333020150000</td>\n",
       "      <td>202</td>\n",
       "      <td>90</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1590</td>\n",
       "      <td>This property, sold on 01/31/2014, is a one-st...</td>\n",
       "      <td>3810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204790</th>\n",
       "      <td>9242030500000</td>\n",
       "      <td>203</td>\n",
       "      <td>80</td>\n",
       "      <td>6650.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>2280</td>\n",
       "      <td>This property, sold on 02/22/2018, is a one-st...</td>\n",
       "      <td>6650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204791</th>\n",
       "      <td>19102030080000</td>\n",
       "      <td>203</td>\n",
       "      <td>30</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>7230</td>\n",
       "      <td>This property, sold on 04/22/2014, is a one-st...</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204792 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PIN  Property Class  Neighborhood Code  Land Square Feet  \\\n",
       "0       17294100610000             203                 50            2500.0   \n",
       "1       13272240180000             202                120            3780.0   \n",
       "2       25221150230000             202                210            4375.0   \n",
       "3       10251130030000             203                220            4375.0   \n",
       "4       31361040550000             202                120            8400.0   \n",
       "...                ...             ...                ...               ...   \n",
       "204787  25163010260000             202                321            4375.0   \n",
       "204788   5063010090000             204                 21           16509.0   \n",
       "204789  16333020150000             202                 90            3810.0   \n",
       "204790   9242030500000             203                 80            6650.0   \n",
       "204791  19102030080000             203                 30            2500.0   \n",
       "\n",
       "        Town Code  Apartments  Wall Material  Roof Material  Basement  \\\n",
       "0              76         0.0            2.0            1.0       1.0   \n",
       "1              71         0.0            2.0            1.0       1.0   \n",
       "2              70         0.0            2.0            1.0       2.0   \n",
       "3              17         0.0            3.0            1.0       1.0   \n",
       "4              32         0.0            3.0            1.0       2.0   \n",
       "...           ...         ...            ...            ...       ...   \n",
       "204787         72         0.0            2.0            1.0       1.0   \n",
       "204788         23         0.0            1.0            1.0       1.0   \n",
       "204789         15         0.0            2.0            1.0       1.0   \n",
       "204790         22         0.0            2.0            1.0       1.0   \n",
       "204791         72         0.0            1.0            1.0       1.0   \n",
       "\n",
       "        Basement Finish  ...  Sale Month of Year  Sale Half of Year  \\\n",
       "0                   3.0  ...                   9                  2   \n",
       "1                   1.0  ...                   5                  1   \n",
       "2                   3.0  ...                   2                  1   \n",
       "3                   3.0  ...                   7                  2   \n",
       "4                   3.0  ...                   6                  1   \n",
       "...                 ...  ...                 ...                ...   \n",
       "204787              1.0  ...                   7                  2   \n",
       "204788              1.0  ...                   3                  1   \n",
       "204789              1.0  ...                   1                  1   \n",
       "204790              3.0  ...                   2                  1   \n",
       "204791              3.0  ...                   4                  1   \n",
       "\n",
       "        Most Recent Sale  Age Decade  Pure Market Filter  Garage Indicator  \\\n",
       "0                    1.0        13.2                   0               0.0   \n",
       "1                    1.0         9.6                   1               1.0   \n",
       "2                    0.0        11.2                   1               1.0   \n",
       "3                    1.0         6.3                   1               1.0   \n",
       "4                    0.0         6.3                   1               1.0   \n",
       "...                  ...         ...                 ...               ...   \n",
       "204787               0.0         5.8                   1               1.0   \n",
       "204788               1.0         9.3                   1               1.0   \n",
       "204789               1.0         5.9                   1               1.0   \n",
       "204790               1.0         6.0                   1               1.0   \n",
       "204791               0.0         4.7                   1               0.0   \n",
       "\n",
       "        Neigborhood Code (mapping)  Town and Neighborhood  \\\n",
       "0                               50                   7650   \n",
       "1                              120                  71120   \n",
       "2                              210                  70210   \n",
       "3                              220                  17220   \n",
       "4                              120                  32120   \n",
       "...                            ...                    ...   \n",
       "204787                         321                  72321   \n",
       "204788                          21                   2321   \n",
       "204789                          90                   1590   \n",
       "204790                          80                   2280   \n",
       "204791                          30                   7230   \n",
       "\n",
       "                                              Description  Lot Size  \n",
       "0       This property, sold on 09/14/2015, is a one-st...    2500.0  \n",
       "1       This property, sold on 05/23/2018, is a one-st...    3780.0  \n",
       "2       This property, sold on 02/18/2016, is a one-st...    4375.0  \n",
       "3       This property, sold on 07/23/2013, is a one-st...    4375.0  \n",
       "4       This property, sold on 06/10/2016, is a one-st...    8400.0  \n",
       "...                                                   ...       ...  \n",
       "204787  This property, sold on 07/23/2014, is a one-st...    4375.0  \n",
       "204788  This property, sold on 03/27/2019, is a one-st...   16509.0  \n",
       "204789  This property, sold on 01/31/2014, is a one-st...    3810.0  \n",
       "204790  This property, sold on 02/22/2018, is a one-st...    6650.0  \n",
       "204791  This property, sold on 04/22/2014, is a one-st...    2500.0  \n",
       "\n",
       "[204792 rows x 62 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba0f6926b0dafefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Part 1: Exploratory Data Analysis\n",
    "\n",
    "In this section, we will make a series of exploratory visualizations and interpret them.\n",
    "\n",
    "Note that we will perform EDA on the **training data** so that information from the test data does not influence our modeling decisions.\n",
    "\n",
    "### Sale Price\n",
    "We begin by examining the distribution of our target variable `SalePrice`.  At the same time, we also take a look at some descriptive statistics of this variable. We have provided the following helper method `plot_distribution` that you can use to visualize the distribution of the SalePrice using both the histogram and the box plot at the same time. Run the following 2 cells and describe what you think is wrong with the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15d483a695655cea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_distribution(data, label):\n",
    "    fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "    sns.distplot(\n",
    "        data[label], \n",
    "        ax=axs[0]\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        data[label],\n",
    "        width=0.3, \n",
    "        ax=axs[1],\n",
    "        showfliers=False,\n",
    "    )\n",
    "\n",
    "    # Align axes\n",
    "    spacer = np.max(data[label]) * 0.05\n",
    "    xmin = np.min(data[label]) - spacer\n",
    "    xmax = np.max(data[label]) + spacer\n",
    "    axs[0].set_xlim((xmin, xmax))\n",
    "    axs[1].set_xlim((xmin, xmax))\n",
    "\n",
    "    # Remove some axis text\n",
    "    axs[0].xaxis.set_visible(False)\n",
    "    axs[0].yaxis.set_visible(False)\n",
    "    axs[1].yaxis.set_visible(False)\n",
    "\n",
    "    # Put the two plots together\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "\n",
    "    # Adjust boxplot fill to be white\n",
    "    axs[1].artists[0].set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(training_data, label='Sale Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 1\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Identify one issue with the visualization above and briefly describe one way to overcome it. You may also want to try running `training_data['Sale Price'].describe()` in a different cell to see some specific summary statistics on the distribution of the target variable.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1i\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Part 2\n",
    "\n",
    "To zoom in on the visualization of most households, we will focus only on a subset of `Sale Price` for this assignment. In addition, it may be a good idea to apply log transformation to `Sale Price`. In the cell below, reassign a new dataframe that is the same as the original one to `training_data` **except with the following changes**:\n",
    "\n",
    "- `training_data` should contain only households whose price is at least $500.\n",
    "- `training_data` should contain a new `Log Sale Price` column that contains the log-transformed sale prices.\n",
    "\n",
    "**Note**: This also implies from now on, our target variable in the model will be the log transformed sale prices from the column `Log Sale Price`. \n",
    "\n",
    "**Note**: You should **NOT** remove the original column `Sale Price` as it will be helpful for later questions.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1ii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new distribution plot on the log-transformed sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(training_data, label='Log Sale Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-592d5f41ebd67ee2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2 \n",
    "\n",
    "### Part 1\n",
    "To check your understanding of the graph and summary statistics above, answer the following `True` or `False` questions:\n",
    "\n",
    "1. The distribution of `Log Sale Price` in the training set is left-skewed.\n",
    "1. The mean of `Log Sale Price` in the training set is greater than the median.\n",
    "1. At least 25% of the houses in the training set sold for more than \\$200,000.00.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2i\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# These should be True or False\n",
    "q2statement1 = ...\n",
    "q2statement2 = ...\n",
    "q2statement3 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e22aac9b45f88e3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Next, we want to explore if any there is any correlation between `Log Sale Price` and the total area occupied by the household. The `codebook.txt` file tells us the column `Building Square Feet` should do the trick -- it measures \"(from the exterior) the total area, in square feet, occupied by the building\".\n",
    "\n",
    "Before creating this jointplot however, let's also apply a log transformation to the `Building Square Feet` column.\n",
    "\n",
    "In the following cell, create a new column `Log Building Square Feet` in our training data that contains the log transformed area occupied by each household. \n",
    "\n",
    "**You should NOT remove the original `Building Square Feet` column this time as it will be used for later questions**. \n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 3\n",
    "\n",
    "As shown below, we created a joint plot with `Log Building Square Feet` on the x-axis, and `Log Sale Price` on the y-axis. In addition, we fit a simple linear regression line through the bivariate scatter plot in the middle.\n",
    "\n",
    "Based on the following plot, does there exist a correlation between `Log Sale Price` and `Log Building Square Feet`? Would `Log Building Square Feet` make a good candidate as one of the features for our model?\n",
    "\n",
    "![Joint Plot](images/q2p3_jointplot.png)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2iii\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e69fbfdd6101f836",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "## Question 3 <a name=\"q2\"></a>\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Although log transformation seems to have done quite a neat job of bringing the dataset closer together, let's still explore some of the outliers in the distribution of `Building Square Feet`. \n",
    "\n",
    "What are the Permanent Indentification Numbers (`PIN`) for the houses with `Building Square Feet` **strictly greater than 8000 sqft**? Assign `q2houses` with a numpy array that contains the PINs for all such houses.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3i\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb0c9f329767dfc2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Hint: You can answer this question in one line\n",
    "q2houses = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf7fe5dcd37df6f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Continuing from the previous part, as you explore the data set, you might still run into more outliers that prevent you from creating a clear visualization or capturing the trend of the majority of the houses. \n",
    "\n",
    "For this assignment, we will work to remove these outliers from the data as we run into them. Write a function `remove_outliers` that removes outliers from a data set based off a threshold value of a variable.  For example, `remove_outliers(training_data, 'Building Square Feet', upper=8000)` should return a data frame with only observations that satisfy `Building Square Feet` less than or equal to 8000.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3ii\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9186ec2ca053d0aa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than this will be removed\n",
    "      upper (numeric): observations with values higher than this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a winsorized data frame with outliers removed\n",
    "      \n",
    "    Note: This function should not change mutate the contents of data.\n",
    "    \"\"\"  \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Part 2: Feature Engineering\n",
    "\n",
    "In this section we will walk you through a few feature engineering techniques. \n",
    "\n",
    "### Bedrooms\n",
    "\n",
    "Let's start simple by extracting the total number of bathrooms as our first feature for the model. You may notice that the `Bedrooms` column doesn't actually exist in the original dataframe! Instead, it is part of the `Description` column.\n",
    "\n",
    "## Question 4 <a name=\"q4\"></a>\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Let's take a closer look at the `Description` column first. Compare the description across a few rows together at the same time. For the following list of variables, how many of them can be extracted from the `Description` column? Assign your answer as an integer to the variable `q4a`.\n",
    "- The date the property was sold on\n",
    "- The number of stories the property contains\n",
    "- The previous owner of the property\n",
    "- The address of the property\n",
    "- The number of garages the property has\n",
    "- The total number of rooms inside the property\n",
    "- The total number of bedrooms inside the property\n",
    "- The total number of bathrooms inside the property\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4i\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4a = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Write a function `add_total_bedrooms(data)` that returns a copy of `data` with an additional column called `Bedrooms` that contains the total number of bathrooms (as integers) for each house. **Treat missing values as zeros if necessary**. Remember that you can make use of vectorized code here; you shouldn't need any `for` statements. \n",
    "\n",
    "**Hint**: You should consider inspecting the `Description` column to figure out if there is any general structure within the text. Once you have noticed a certain pattern, you are set with the power of Regex!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4ii\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_bedrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least the Description column.\n",
    "    \"\"\"\n",
    "    with_rooms = data.copy()\n",
    "    ...\n",
    "    return with_rooms\n",
    "\n",
    "training_data = add_total_bedrooms(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 3\n",
    "\n",
    "Create a visualization that clearly and succintly shows if there exists an association between  `Bedrooms` and `Log Sale Price`. A good visualization should satisfy the following requirements:\n",
    "- It should avoid overplotting.\n",
    "- It should have clearly labeled axes and succinct title.\n",
    "- It should convey the strength of the correlation between the sale price and the number of rooms. \n",
    "\n",
    "**Hint**: A direct scatter plot of the sale price against the number of rooms for all of the households in our training data might risk overplotting.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4iii\n",
    "points: 2\n",
    "manual: True\n",
    "format: image\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the relationship between neighborhood and sale prices of the houses in our data set.\n",
    "Notice that currently we don't have the actual names for the neighborhoods. Instead we will use a similar column `Neighborhood Code` (which is a numerical encoding of the actual neighborhoods by the Assessment office)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 1\n",
    "\n",
    "Before creating any visualization, let's quickly inspect how many different neighborhoods we are dealing with.\n",
    "\n",
    "Assign the variable `num_neighborhoods` with the total number of neighborhoods in `training_data`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5i\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighborhoods = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part  2\n",
    "\n",
    "If we try directly plotting the distribution of `Log Sale Price` for all of the households in each neighborhood using the `plot_categorical` function from the next cell, we would get the following visualization.\n",
    "![overplot](images/q5p2_catplot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_categorical(neighborhoods, data, with_filter=True):\n",
    "    if not with_filter:\n",
    "        neighborhoods = data\n",
    "    fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "    sns.boxplot(\n",
    "        x='Neighborhood Code',\n",
    "        y='Log Sale Price',\n",
    "        data=neighborhoods.sort_values('Neighborhood Code'),\n",
    "        ax=axs[0],\n",
    "    )\n",
    "\n",
    "    sns.countplot(\n",
    "        x='Neighborhood Code',\n",
    "        data=neighborhoods.sort_values('Neighborhood Code'),\n",
    "        ax=axs[1],\n",
    "    )\n",
    "\n",
    "    # Draw median price\n",
    "    axs[0].axhline(\n",
    "        y=data['Log Sale Price'].median(), \n",
    "        color='red',\n",
    "        linestyle='dotted'\n",
    "    )\n",
    "\n",
    "    # Label the bars with counts\n",
    "    for patch in axs[1].patches:\n",
    "        x = patch.get_bbox().get_points()[:, 0]\n",
    "        y = patch.get_bbox().get_points()[1, 1]\n",
    "        axs[1].annotate(f'{int(y)}', (x.mean(), y), ha='center', va='bottom')\n",
    "\n",
    "    # Format x-axes\n",
    "    axs[1].set_xticklabels(axs[1].xaxis.get_majorticklabels(), rotation=90)\n",
    "    axs[0].xaxis.set_visible(False)\n",
    "\n",
    "    # Narrow the gap between the plots\n",
    "    plt.subplots_adjust(hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Oh no, looks like we have run into the problem of overplotting again! \n",
    "\n",
    "You might have noticed that the graph is overplotted because **there are actually quite a few neighborhoods in our dataset**! For the clarity of our visualization, we will have to zoom in again on a few of them. The reason for this is our visualization will become quite cluttered with a super dense x-axis.\n",
    "\n",
    "Assign the variable `top_20_neighborhoods` with a copy of `training_data` that contains only neighborhoods with the top 20 number of buildings. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5ii\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_neighborhoods = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another of the distribution of sale price within in each neighborhood again, but this time with a narrower focus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical(neighborhoods=top_20_neighborhoods, data=training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 3\n",
    "\n",
    "It looks a lot better now than before, right? Based on the plot above, what can be said about the relationship between the houses' `Log Sale Price` and their neighborhoods?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5iii\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Part 4\n",
    "\n",
    "One way we can deal with the lack of data from some neighborhoods is to create a new feature that bins neighborhoods together.  Let's categorize our neighborhoods in a crude way: we'll take the top 3 neighborhoods measured by median `Log Sale Price` and identify them as \"expensive neighborhoods\"; the other neighborhoods are not marked.\n",
    "\n",
    "Write a function that returns list of the top `n` most pricy neighborhoods as measured by our choice of aggregating function.  For example, in the setup above, we would want to call `find_expensive_neighborhoods(training_data, 3, np.median)` to find the top 3 neighborhoods measured by median `Log Sale Price`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5iv\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_expensive_neighborhoods(data, n=3, metric=np.median):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): should contain at least a string-valued Neighborhood\n",
    "        and a numeric 'Sale Price' column\n",
    "      n (int): the number of top values desired\n",
    "      metric (function): function used for aggregating the data in each neighborhood.\n",
    "        for example, np.median for median prices\n",
    "    \n",
    "    Output:\n",
    "      a list of the top n richest neighborhoods as measured by the metric function\n",
    "    \"\"\"\n",
    "    neighborhoods = ...\n",
    "    \n",
    "    # This makes sure the final list contains the generic int type used in Python3, not specific ones used in numpy.\n",
    "    return [int(code) for code in neighborhoods]\n",
    "\n",
    "expensive_neighborhoods = find_expensive_neighborhoods(training_data, 3, np.median)\n",
    "expensive_neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 5\n",
    "We now have a list of neighborhoods we've deemed as richer than others.  Let's use that information to make a new variable `in_expensive_neighborhood`.  Write a function `add_expensive_neighborhood` that adds an indicator variable which takes on the value 1 if the house is part of `expensive_neighborhoods` and the value 0 otherwise.\n",
    "\n",
    "**Hint:** [`pd.Series.astype`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.astype.html) may be useful for converting True/False values to integers.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5v\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_expensive_neighborhood(data, neighborhoods):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Neighborhood Code' column with values\n",
    "        found in the codebook\n",
    "      neighborhoods (list of strings): strings should be the names of neighborhoods\n",
    "        pre-identified as rich\n",
    "    Output:\n",
    "      data frame identical to the input with the addition of a binary\n",
    "      in_rich_neighborhood column\n",
    "    \"\"\"\n",
    "    data['in_expensive_neighborhood'] = ...\n",
    "    return data\n",
    "\n",
    "expensive_neighborhoods = find_expensive_neighborhoods(training_data, 3, np.median)\n",
    "training_data = add_in_expensive_neighborhood(training_data, expensive_neighborhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following question, we will take a closer look at the `Roof Material` feature of the dataset and examine how we can incorporate categorical features into our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 1\n",
    "\n",
    "If we look at the codebook carefully, we can see that the Assessor's Office uses the following mapping for the numerical values in the `Roof Material` column.\n",
    "```\n",
    "Central Heating (Nominal): \n",
    "\n",
    "       1\tShingle/Asphalt\n",
    "       2\tTar&Gravel\n",
    "       3\tSlate\n",
    "       4\tShake\n",
    "       5    Tile\n",
    "       6    Other\n",
    "```\n",
    "\n",
    "Write a function `substitute_roof_material` that replaces each numerical value in `Roof Material` with their corresponding roof material.\n",
    "\n",
    "**Hint**: the [DataFrame.replace](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) method may be useful here.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6i\n",
    "points: 1\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_roof_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return data\n",
    "    \n",
    "training_data = substitute_roof_material(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### An Important Note on One Hot Encoding <a name=\"important_note\"></a>\n",
    "\n",
    "Unfortunately, simply fixing these missing values isn't sufficient for using `Roof Material` in our model.  Since `Roof Material` is a categorical variable, we will have to one-hot-encode the data.  Notice in the example code below that we have to pre-specify the categories.  Why? Imagine what would happen if we automatically generated the categories only from the training data.  What would happen if the testing data contained a category not found in the training set?  For more information on categorical data in pandas, refer to this [link](https://pandas-docs.github.io/pandas-docs-travis/categorical.html).\n",
    "\n",
    "Complete the following function `ohe_roof_material` that returns a dataframe with the new column one-hot-encoded on the roof material of the household. The new column should has the form `rfm_MATERIAL`.\n",
    "\n",
    "**Note**: You should **avoid using `pd.get_dummies`** in your solution as it will remove your original column and is therefore not as reusable as your construct your data preprocessing pipeline. Instead, you can one-hot-encode one column into multiple columns **using Scikit-learn's [One Hot Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)**.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6ii\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def ohe_roof_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "training_data = ohe_roof_material(training_data)\n",
    "training_data.filter(regex='^x0').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ffdfab3f8801658",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 3: Modeling\n",
    "\n",
    "We've reached the point where we can specify a model.\n",
    "\n",
    "Before moving forward, let's actually make sure out dataset is properly prepared. Please make sure that the assertion statements in the following cell pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert training_data.shape == (168931, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, let's reassign `training_data` to a new variable `full_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Question 7 <a name=\"q6\"></a>\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Now, let's split the data set into a training set and test set. We will use the training set to fit our model's parameters, and we will use the test set to estimate how well our model will perform on unseen data drawn from the same distribution. If we used all the data to fit our model, we would not have a way to estimate model performance on unseen data.\n",
    "\n",
    "\"Don't we already have a test set in `cook_county_test.csv`?\" you might wonder. The sale prices for `cook_county_test.csv` aren't provided, so we're constructing our own test set for which we know the outputs.\n",
    "\n",
    "In the cell below, complete the function `train_test_split` that splits `data` into two smaller DataFrames named `train` and `test`. Let `train` contain 80% of the data, and let `test` contain the remaining 20% of the data. \n",
    "\n",
    "To do this, first create two NumPy arrays named `train_indices` and `test_indices`. `train_indices` should contain a *random* 80% of the indices in `full_data`, and `test_indices` should contain the remaining 20% of the indices. Then, use these arrays to index into `full_data` to create your final `train` and `test` DataFrames.\n",
    "\n",
    "\n",
    "**Note**: You should not be importing any additional libraries for this question. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7i\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_test_split in general\n",
    "\n",
    "# DO NOT CHANGE THIS LINE\n",
    "np.random.seed(1337)\n",
    "# DO NOT CHANGE THIS LINE\n",
    "\n",
    "def train_test_split(data):\n",
    "    data_len = data.shape[0]\n",
    "    shuffled_indices = np.random.permutation(data_len)\n",
    "    ...\n",
    "train, test = train_test_split(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's finally time to fit our updated linear regression model using the ordinary least squares estimator! We will start you off with something simple by using only 2 features: the **number of bedrooms** in the household and the **log-transformed total area covered by the building** (in square feet). \n",
    "\n",
    "Consider the following expression for our 1st linear model that contains one of the features:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms})\n",
    "$$\n",
    "\n",
    "In parallel, we will also consider a 2nd model that contains both features:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms}) + \\theta_2 \\cdot (\\text{Log Building Square Feet})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 2\n",
    "\n",
    "**Without running any calculation or code**, complete the following statement by filling in the blank with one of the  comparators below:\n",
    "\n",
    "$$\\ge$$\n",
    "$$\\le$$\n",
    "$$=$$\n",
    "\n",
    "Suppose we quantify the loss on our linear models using MSE (Mean Squared Error). Consider the training loss of the 1st model and the training loss of the 2nd model. We are guaranteed that:\n",
    "\n",
    "$$\n",
    "\\text{Training Loss of the 1st Model}  \\_\\_\\_\\_\\_  \\text{Training Loss of the 2nd Model}\n",
    "$$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7ii\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acdc861fd11912e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Throughout this assignment, you should notice that your data flows through a single processing pipeline several times.  From a software engineering perspective, it's best to define functions/methods that can apply the pipeline to any dataset.  We will now encapsulate our entire pipeline into a single function `process_data_gm`. \n",
    "\n",
    "Take a look at the following function `process_data_gm` that takes in the dataframe `data`, a list `pipeline_functions` containing 3-element tuples `(function, arguments, keyword_arguments)` that will be called on `data` in the pipeline, and the label `prediction_col` that represents the column of our target variable (`Sale Price` in this case). It returns two dataframes: `X`, which is our design matrix, and `y` which is the vector containing the observed data.\n",
    "\n",
    "To see more of how this function can be used, please see the example below the next cell.\n",
    "\n",
    "Take a look at [pd.DataFrame.pipe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html); you can use this function with each of the tuples passed in through `pipeline_functions`.\n",
    "\n",
    "**Note: As there are many ways to encapsulate your workflow in a way that works best for you, you are not required to follow the setup below as you prepare your own data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2fe1d82b2c19d1fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def process_data_gm(data, pipeline_functions, prediction_col):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    for function, arguments, keyword_arguments in pipeline_functions:\n",
    "        if keyword_arguments and (not arguments):\n",
    "            data = data.pipe(function, **keyword_arguments)\n",
    "        elif (not keyword_arguments) and (arguments):\n",
    "            data = data.pipe(function, *arguments)\n",
    "        else:\n",
    "            data = data.pipe(function)\n",
    "    X = data.drop(columns=[prediction_col]).to_numpy()\n",
    "    y = data.loc[:, prediction_col].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this cell again to make sure the train-test split is reproducible across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 3\n",
    "\n",
    "It is time to prepare the training and test data for the 2 models we proposed above. Use the following 3 cells to reload a fresh dataset from scratch and run them through the following preprocessing steps for each model:\n",
    "\n",
    "- Perform a train-test split on the original dataset. Let 80% of the set be training data and 20% of the set be test data.\n",
    "- For both the training and testing set,\n",
    "    1. Remove outliers in `Sale Price` by so that we are considering households with a price that is strictly greater than 499 dollars (i.e., greater than or equal to 500 dollars). \n",
    "    2. Apply log transformations to `Sale Price` and the `Building Squre Feet` columns to create 2 new columns `Log Sale Price` and `Log Building Square Feet`.\n",
    "    3. Extract the total number of bathrooms into a new column `Bedrooms` from the `Description` column.\n",
    "    4. Select the columns `Log Sale Price` and `Bedrooms` (and `Log Building Square Feet` as well if this is the 2nd model).\n",
    "    5. Return the design matrix $X$ and the observed vector $y$. **Your design matrix and observed vector should either be numpy arrays or pandas dataframes**.\n",
    "    \n",
    "\n",
    "Assign the final training data and testing data for both models to the following set of variables:\n",
    "\n",
    "- 1st Model: `X_train_m1`, `y_train_m1`, `X_test_m1`, `y_test_m1`\n",
    "- 2nd Model: `X_train_m2`, `y_train_m2`, `X_test_m2`, `y_test_m2`\n",
    "   \n",
    "**Hint**: You have already defined functions in parts of the assignment that can help you accomplish these steps.\n",
    "\n",
    "**Hint**: If you are not following the example approach shown above in `process_data_gm`, it could be helpful to define your function that encapsulates all of the preprocessing you need to call on the data.\n",
    "\n",
    "**Hint**: Try to start by preparing the data for the first model. The steps should be very similar for the second model.\n",
    "\n",
    "**Note**: Do not change the line `np.random.seed(1337)` as it ensures we are partitioning the dataset exactly the same way for both models (otherwise their performance isn't directly comparable).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7iii\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and preprocess the data for 1st model\n",
    "full_data = pd.read_csv(\"cook_county_train.csv\")\n",
    "\n",
    "# Reload and preprocess the data for the 1st model\n",
    "...\n",
    "X_train_m1, y_train_m1, X_test_m1, y_test_m1 = ..., ..., ..., ...\n",
    "\n",
    "\n",
    "# DO NOT CHANGE THIS LINE\n",
    "np.random.seed(1337)\n",
    "# DO NOT CHANGE THIS LINE\n",
    "\n",
    "# Reload and preprocess the data for 2nd model\n",
    "...\n",
    "X_train_m2, y_train_m2, X_test_m2, y_test_m2 = ..., ..., ..., ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "Finally, let's do some regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object for both of our models. We set the `fit_intercept = True` to ensure that the linear model has a non-zero intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "linear_model_m1 = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model_m2 = lm.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the 1st model\n",
    "# Compute the fitted and predicted values of Sale Price for 1st model\n",
    "y_fitted_m1 = ...\n",
    "y_predicted_m1 = ...\n",
    "\n",
    "# Fit the 2nd model\n",
    "# Compute the fitted and predicted values of Sale Price for 1st model\n",
    "y_fitted_m2 = ...\n",
    "y_predicted_m2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "\n",
    "Let's compare the performance of our two regression models using the Root Mean Squared Error function that we created in Homework 5.\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in test set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{number of of houses}}}$$\n",
    "\n",
    "The function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "      actual (1D array): vector of actual values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now use your `rmse` function to calculate the training error and test error for both models in the cell below.\n",
    "\n",
    "Assign the error from both of your models to the following variables:\n",
    "\n",
    "- 1st model: `training_error_m1`, `test_error_m1`\n",
    "- 2nd model: `training_error_m2`, `test_error_m2`\n",
    "\n",
    "Since the target variable we are working with is log-transformed, it can also be beneficial to transform it back to its original form so we will have more context on how our model is performing when compared to actual housing prices.\n",
    "\n",
    "Assign the error on the \"de-log-transformed\" sale price from both of your models to the following variables:\n",
    "\n",
    "- 1st model: `training_error_m1_delog`, `test_error_m1_delog`\n",
    "- 2nd model: `training_error_m2_delog`, `test_error_m2_delog`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7v\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test errors for the 1st model\n",
    "training_error_m1 = ...\n",
    "test_error_m1 = ...\n",
    "\n",
    "# Training and test errors for the 1st model (in its original values before the log transform)\n",
    "training_error_m1_delog = ...\n",
    "test_error_m1_delog = ...\n",
    "\n",
    "\n",
    "# Training and test errors for the 2nd model\n",
    "training_error_m2 = ...\n",
    "test_error_m2 = ...\n",
    "\n",
    "\n",
    "# Training and test errors for the 2nd model (in its original values before the log transform)\n",
    "training_error_m2_delog = ...\n",
    "test_error_m2_delog = ...\n",
    "\n",
    "print(\"1st Model\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m1, test_error_m1))\n",
    "print(\"1st Model (no log transform)\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m1_delog, test_error_m1_delog))\n",
    "print(\"2nd Model\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m2, test_error_m2))\n",
    "print(\"2nd Model (no log transform)\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m2_delog, test_error_m2_delog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 6\n",
    "\n",
    "Let's compare the actual parameters ($\\theta_0$ and $\\theta_1$) from both of our models. As a quick reminder,\n",
    "\n",
    "for the 1st model,\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms})\n",
    "$$\n",
    "\n",
    "for the 2nd model,\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms}) + \\theta_2 \\cdot (\\text{Log Building Square Feet})\n",
    "$$\n",
    "\n",
    "Run the following cell and compare the values of $\\theta_1$ from both models. Why does $\\theta_1$ change from positive to negative when we introduce an additional feature in our 2nd model? \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7vi\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters from 1st model\n",
    "theta0_m1 = linear_model_m1.intercept_\n",
    "theta1_m1 = linear_model_m1.coef_[0]\n",
    "\n",
    "# Parameters from 2nd model\n",
    "theta0_m2 = linear_model_m2.intercept_\n",
    "theta1_m2, theta2_m2 = linear_model_m2.coef_\n",
    "\n",
    "print(\"1st Model\\nθ0: {}\\nθ1: {}\".format(theta0_m1, theta1_m1))\n",
    "print(\"2nd Model\\nθ0: {}\\nθ1: {}\\nθ2: {}\".format(theta0_m2, theta1_m2, theta2_m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a359da2dda38fcdd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 7\n",
    "\n",
    "Another way of understanding the performance (and appropriateness) of a model is through a residual plot. \n",
    "\n",
    "In the cell below, use `plt.scatter` to plot the predicted `Log Sale Price` from **only the 2nd model** against the original `Log Sale Price` for the test data. You should also ensure that the dot size and opacity in the scatter plot are set appropriately to reduce the impact of overplotting.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7vii\n",
    "points: 2\n",
    "manual: True\n",
    "format: image\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d79f42d60b94fca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "As you can see, our simple model has already got off to a good start, but there is certainly still a lot of room for improvement to be made -- one simple reason is we have been only utilizing 1 or 2 features (out of a total of 70+) so far! Can you engineer and incoporate more features to improve the model's accuracy? We won't be asking you to provide your answers here, but this would be important going into the next part of this project."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "编辑元数据",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
