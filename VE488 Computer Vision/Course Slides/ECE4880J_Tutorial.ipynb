{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE4880J_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Python Tutorial for ECE4880J (Coding part)\n",
        "\n",
        "This tutorial is written by Yueyuan for ECE4880J in SJTU-UMJI. It runs Python3 by default."
      ],
      "metadata": {
        "id": "_uisN54ow4D0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this tutorial, we will cover:\n",
        "\n",
        "- Basic Python\n",
        "- Numpy $\\to$ (extend) $\\to$ Scipy\n",
        "- Matplotlib $\\leftarrow$ (compare) $\\rightarrow$ OpenCV, PIL\n",
        "- Pytorch"
      ],
      "metadata": {
        "id": "zuNiOqP3_31s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About Jupyter Notebook\n",
        "\n",
        "Jupyter is a web-based interactive development environment. The two basic components in a Jupyter botebook are code block and text block. In the code block, you can execute over 40 programming languages, including Python, R, Julia, and Scala. In the text block, you can produce rich text format content, including HTML, LateX, and Markdown. The modular design of Jupyter Notebook allows extensions to expand and enrich functionality.\n",
        "\n",
        "For more details about Jupyter Notebook, you can visit its official ducumentation [here](https://docs.jupyter.org/en/latest/).\n",
        "\n",
        "#### Checklist\n",
        "\n",
        "- Select Python path.\n",
        "- Add, delete, and move the blocks.\n",
        "- Clear output.\n",
        "- Restart kernel."
      ],
      "metadata": {
        "id": "AJbbdAqLAgrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Routine checkup before running python\n",
        "\n",
        "Before every first time you run a new python script, I strongly suggest you should check the path you are under, the python version, and the package manager version.\n",
        "\n",
        "```![command]``` means that the line is a Terminal command."
      ],
      "metadata": {
        "id": "dPRs-c_ZATj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "T9blCoT21UbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!pip --version"
      ],
      "metadata": {
        "id": "ty53gdXGw_bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are to run some open source code, please always remember to install the required packages first.\n",
        "\n",
        "```shell\n",
        "pip install -r requirements.txt\n",
        "```"
      ],
      "metadata": {
        "id": "QhGSsLi3I1w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this block to install all the package we need for this tutorial\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n",
        "!pip install opencv-python\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "# in case you use conda\n",
        "# !conda install numpy\n",
        "# !conda install pandas\n",
        "# !conda install scipy\n",
        "# !conda install matplotlib\n",
        "# !conda install pillow\n",
        "# !conda install opencv-python\n",
        "# !conda install torch\n",
        "# !conda install torchvision"
      ],
      "metadata": {
        "id": "3zkNW1XDxBCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Python (checklist)"
      ],
      "metadata": {
        "id": "1llBZdsXKhkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Indentation is important for python.\n",
        "- You do not have to declare the data type of a variable before using it."
      ],
      "metadata": {
        "id": "MWBwpHFrQ-iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I do not encourage you to assign value to a variable like this, but it works in Python.\n",
        "def declare_variable(input=None):\n",
        "    if input == 1:\n",
        "        a = 1\n",
        "    else:\n",
        "        a = 0\n",
        "    print(a)\n",
        "\n",
        "declare_variable(1)\n",
        "declare_variable()"
      ],
      "metadata": {
        "id": "aNHkmDFzQySu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The data type of a variable can be changed at any time."
      ],
      "metadata": {
        "id": "ljvTHv7iTFq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = int(1)\n",
        "print(a, end=\", \")\n",
        "a = \"a\"\n",
        "print(a, end=\", \")\n",
        "a = float(1)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "E2hi0JObTFCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In a python list, the data type of the elements do not have to be the same."
      ],
      "metadata": {
        "id": "YxD6XOsHT2yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = [int(42), float(3.14), \"Matt Bomber\", {\"wagtail\"}, {1: \"2\"}]\n",
        "b"
      ],
      "metadata": {
        "id": "slnYpMI5T2T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Check an instance's data type by ```isinstance```"
      ],
      "metadata": {
        "id": "NnmPsvKioHhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(isinstance(b, type(list)))"
      ],
      "metadata": {
        "id": "M6tHri-BnMoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Assignment statements in Python do not copy objects, they create bindings between a target and an object. \n",
        "\n",
        "  **Be carefull when you copy a variable!**\n",
        "\n",
        "  (I only demo ```copy()```. Please check ```deepcopy()``` [here](https://docs.python.org/3/library/copy.html) by yourself)"
      ],
      "metadata": {
        "id": "Jp5VsKKZogKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 1\n",
        "list1 = [1,2,3,4,5]\n",
        "list2 = list1\n",
        "list2[0] = 0\n",
        "print(list1, list2)"
      ],
      "metadata": {
        "id": "d19ztdCZofWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# case 2\n",
        "list1 = [1,2,3,4,5]\n",
        "list2 = list1.copy() # or list2 = list1[:]\n",
        "list2[0] = 0\n",
        "print(list1, list2)"
      ],
      "metadata": {
        "id": "lxHrJEPQo6Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# case 3\n",
        "def change_first_element(list_test:list):\n",
        "    list_test[0] = 0\n",
        "\n",
        "list1 = [1,2,3,4,5]\n",
        "list2 = list1\n",
        "change_first_element(list2)\n",
        "print(list1, list2)"
      ],
      "metadata": {
        "id": "duIVt3zBpHt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# case 4\n",
        "def change_first_element(list_test:list):\n",
        "    list_test[0] = 0\n",
        "\n",
        "list1 = [1,2,3,4,5]\n",
        "list2 = list1.copy()\n",
        "change_first_element(list2)\n",
        "print(list1, list2)"
      ],
      "metadata": {
        "id": "JVRWMqutrdXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Inline if-else"
      ],
      "metadata": {
        "id": "Mx8b7HMwU8Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ECE4880J = True\n",
        "i_want_to_sleep = True if not ECE4880J else False\n",
        "print(i_want_to_sleep)"
      ],
      "metadata": {
        "id": "5ky4zTheTX7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Inline loop"
      ],
      "metadata": {
        "id": "ELjewOl-Wx8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assignment_is_hard = [False, False, False]\n",
        "assignment_is_finished = [not x for x in assignment_is_hard]\n",
        "print(assignment_is_hard, assignment_is_finished)"
      ],
      "metadata": {
        "id": "46bG2tT7W-da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- More code samples about basic data types (list, dictionary, set, tuple) can be found [here](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb)."
      ],
      "metadata": {
        "id": "iVB20BYgy-54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy\n",
        "\n",
        "> NumPy (**Numerical Python**) is an open source Python library...It’s the universal standard for working with numerical data in Python, and it’s at the core of the scientific Python and PyData ecosystems...The NumPy API is used extensively in Pandas, SciPy, Matplotlib, scikit-learn, scikit-image and most other data science and scientific Python packages. <br><br> from the *Official Numpy Documentation*\n",
        "\n",
        "![](https://bids.berkeley.edu/sites/default/files/2020-0916-numpy-nature-fig2.png)\n"
      ],
      "metadata": {
        "id": "k3qShp8t69Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "YsBAnwUMOdlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ```np.ndarray``` vs. ```list```"
      ],
      "metadata": {
        "id": "LRqfVWVQ1Yha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Initialize an array with arbitrary length"
      ],
      "metadata": {
        "id": "2fsJ8f7033yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "sample_list = [5] * n\n",
        "sample_np = np.ones(5) * n\n",
        "print(sample_list, sample_np)"
      ],
      "metadata": {
        "id": "W_MrAMPL1qfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Generate an array with evenly spaced intervals"
      ],
      "metadata": {
        "id": "OQfolZZZ3-zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_list = [*range(0,6,2)]\n",
        "sample_np = np.arange(0,6,2)\n",
        "print(sample_list, sample_np)"
      ],
      "metadata": {
        "id": "I45SaGW_2ZdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The step in range() must be an interger.\n",
        "sample_list = [*range(0,6,0.5)]"
      ],
      "metadata": {
        "id": "3NzSXl1y3Z0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You have more freedom when generating an array with numpy\n",
        "sample_np = np.arange(0,6,0.5)\n",
        "print(sample_np)"
      ],
      "metadata": {
        "id": "bXjZFF-g3nzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Adding elements"
      ],
      "metadata": {
        "id": "g_pSRdCV4D55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add one element to a list\n",
        "sample_list.append(5)\n",
        "print(sample_list)"
      ],
      "metadata": {
        "id": "gDJqwxQd4Lx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate two lists\n",
        "print(sample_list + [1,2,3])"
      ],
      "metadata": {
        "id": "DLvhhLnS4jMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In numpy, you only have concatenate\n",
        "print(np.concatenate((sample_np, np.zeros(3))))"
      ],
      "metadata": {
        "id": "PjIhki9D5EJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy only concatenate arrays with the same shape\n",
        "print(np.concatenate((np.ones((3,2)), np.zeros((4,2)))))"
      ],
      "metadata": {
        "id": "7cdxyq4A5d8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.concatenate((np.ones((3,2)), np.zeros((4,3)))))"
      ],
      "metadata": {
        "id": "I22ITtiT6CUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can concatenate numpy arrays along different axis.\n",
        "print(np.concatenate((np.ones((3,2)), np.zeros((3,2))), axis=1))"
      ],
      "metadata": {
        "id": "YNO17jzv6Ki_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. The shape and size of an array"
      ],
      "metadata": {
        "id": "XIkodhXt6l6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can only check the length of a list\n",
        "sample_list = [[1,2], [3,4], [5,6]]\n",
        "print(len(sample_list))"
      ],
      "metadata": {
        "id": "fUvJ40I06lbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can check the dimension, total number of elements, and the shape of a np.ndarray\n",
        "sample_np = np.array(sample_list)\n",
        "print(sample_np.ndim, sample_np.size, sample_np.shape)"
      ],
      "metadata": {
        "id": "GrpeTdoSALzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Basic array operations"
      ],
      "metadata": {
        "id": "fJSBPdBF_3HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"+\" operation in a python list means joining the lists.\n",
        "# You cannot apply \"+\" to a list and an element\n",
        "print([1,2,3,4] + 1)"
      ],
      "metadata": {
        "id": "foaj02Rn_04a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"+\" can be applied to \n",
        "print(np.array([1,2,3,4]) + 1)\n",
        "print(np.array([1,2,3,4]) + np.ones(4))"
      ],
      "metadata": {
        "id": "nRUtWOVhAgBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"*\" is used to enlarge the list size \n",
        "print([1,2] * 5)"
      ],
      "metadata": {
        "id": "58wSojTRDZCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In numpy, you can see three different products\n",
        "print(np.array([1,2,3]) * 2)\n",
        "print(np.array([1,2,3]) * np.array([4,5,6])) # multiply element by element\n",
        "print(np.dot([1,2,3], [4,5,6])) # dot product\n",
        "print(np.cross([1,2,3], [4,5,6])) # cross product"
      ],
      "metadata": {
        "id": "sH7vXxmMD1IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specialties of Numpy"
      ],
      "metadata": {
        "id": "0M3KSwMUE-x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Reshape an array"
      ],
      "metadata": {
        "id": "kqx_7QW6MBDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_np = np.arange(6)\n",
        "print(sample_np)\n",
        "print(sample_np.reshape(2,3))"
      ],
      "metadata": {
        "id": "A8nkzW1cE9kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Select elements"
      ],
      "metadata": {
        "id": "2nnknUXeMUqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_np[sample_np % 2 == 0])\n",
        "print(sample_np[(sample_np > 2) & (sample_np < 5)])"
      ],
      "metadata": {
        "id": "rs_1-U-PMf0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Transpose"
      ],
      "metadata": {
        "id": "V4wYgdSIM-76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_np = sample_np.reshape(2,3)\n",
        "print(sample_np)\n",
        "print(sample_np.T)"
      ],
      "metadata": {
        "id": "I9AldEEAM9up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Reverse"
      ],
      "metadata": {
        "id": "WMXavbOONRX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.flip(sample_np, axis=0))\n",
        "print(np.flip(sample_np, axis=1))"
      ],
      "metadata": {
        "id": "5Gh7QvOANTR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Powerful APIs\n",
        "\n",
        "You can search for the details [here](https://numpy.org/doc/1.22/reference/index.html).\n",
        "\n",
        "- Mathematical functions: sin, cos, exp, sum, max, min, etc.\n",
        "- Sorting, searching, and counting\n",
        "- Discrete Fourier Transform (```numpy.fft``` module)\n",
        "    \n",
        "    Fast Fourier Transform is widely used to restore an image with noise.\n",
        "    \n",
        "    <img src=\"https://kirkt.smugmug.com/photos/45700484_3hrU5-L.jpg\" width=\"500px\" />\n",
        "- Linear algebra (```numpy.linalg``` module)\n",
        "- Masked array operations"
      ],
      "metadata": {
        "id": "N_RyA2K-Np9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scipy"
      ],
      "metadata": {
        "id": "V1H_25lW7D5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> SciPy (**Scientific Python**) is a free and open-source Python library used for scientific computing and technical computing. <br> SciPy contains modules for optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing, ODE solvers and other tasks common in science and engineering... <br> The basic data structure used by SciPy is a multidimensional array provided by the **NumPy** module. <br> <br> from *Wikipeida*"
      ],
      "metadata": {
        "id": "Ee-Zbrzkgv0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the submodules we may frequently use for this course:\n",
        "\n",
        "- scipy.fft: Discrete Fourier Transform algorithms\n",
        "- scipy.signal: signal processing tools\n",
        "- scipy.linalg: linear algebra routines\n",
        "- scipy.ndimage: various functions for multi-dimensional image processing\n",
        "- scipy.io: data input and output"
      ],
      "metadata": {
        "id": "_d83m7SNmbNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from scipy import signal"
      ],
      "metadata": {
        "id": "Zfo5-KU06HSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matplotlib"
      ],
      "metadata": {
        "id": "GSC-_b0p7BPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Differences between matplotlib, PIL, and OpenCV\n",
        "\n",
        "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. It is written in Python and C++. It focuses more on **visualization**. Its ability to process an image is relatively weak.\n",
        "\n",
        "Pillow and OpenCV are image libraires for loading, processing, and creating images. They provide the implemenetation of many classical image processing methods. \n",
        "- Pillow is written in Python and C, while OpenCV is written in C++ and C. In most of the cases, OpenCV is faster.\n",
        "- Pillow reads the images in BGR format by default. OpenCV reads the images in RGB format by default.\n",
        "- Both of these two libraries provide tools for\n",
        "\n",
        "    - Image filters (blur, sharpen, etc.）\n",
        "    - Image transformation (filp, rotate, warp, etc.)\n",
        "    - Conversion between image types\n",
        "\n",
        "- OpenCV also provides\n",
        "\n",
        "    - Tools to process videos\n",
        "    - Feature extraction methods (SIFT, HOG, HAAR, etc.)\n",
        "    - Classical machine learning models (Bayes classifier, KNN, SVM, etc.)"
      ],
      "metadata": {
        "id": "C9qgHOU-UYPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Be careful of your backend!\n",
        "\n",
        "If your image is not plotted as expected while there is not any error reported, the problem is very likely on your selection of backend!\n",
        "\n",
        "The Matplotlib architecture is composed of three main layers:\n",
        "\n",
        "- Backend Layer: Handles all the heavy works via communicating to the drawing toolkits in your machine. It is the most complex layer.\n",
        "- Artist Layer: Allows full control and fine-tuning of the Matplotlib figure, the top-level container for all plot elements.\n",
        "- Scripting Layer: The lightest scripting interface among the three layers, designed to make Matplotlib work like MATLAB script."
      ],
      "metadata": {
        "id": "887Jw3oA7JiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import PIL"
      ],
      "metadata": {
        "id": "gRo7YHz9Oj1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib --list"
      ],
      "metadata": {
        "id": "leK707qgthWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matplotlib.get_backend()"
      ],
      "metadata": {
        "id": "lmWw1CqEsZ8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structure of a plot in matplotlib\n",
        "\n",
        "![](https://3.bp.blogspot.com/-AtPG_12l4e8/XRSuQEECZGI/AAAAAAAAHxY/ZsgtA4rMphMZujcWUur9BB-xYKoWDkKPQCLcBGAs/s1600/basics_matplotlib.PNG)\n",
        "\n"
      ],
      "metadata": {
        "id": "6Oo3NohqcS3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution\n",
        "\n",
        "Convolution is the process of adding each element of the image to its local neighbors, weighted by the kernel. This operation is widely use in image processing.\n",
        "\n",
        "<img src=\"https://assets.leetcode.com/users/images/a7e6370b-84cb-4e9a-861a-deceb8064a07_1599380839.3085368.png\" width=\"500px\" />"
      ],
      "metadata": {
        "id": "PX02eCkHz5PW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application 1: Extract features\n",
        "\n",
        "<img src=\"https://s2.loli.net/2022/05/25/rbo15VqQT7PxgcX.png\" width=\"500px\" />\n"
      ],
      "metadata": {
        "id": "yEL39TNQ2DwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we load an online image\n",
        "f_name, _ = urllib.request.urlretrieve(\n",
        "    \"https://www.kindpng.com/picc/m/134-1342850_logo-harry-potter-hogwarts-png-download-logo-hogwarts.png\", \n",
        "    \"SJTU.png\")\n",
        "img = plt.imread(f_name)\n",
        "print(img.shape)\n",
        "img = img[:,:,:3]\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "oSy6V67w2DTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HarrisCorner(img, k=0.1):\n",
        "    G_x = np.array([[-1,0,1], [-2,0,2], [-1,0,1]]) # Sobel operator on x direction\n",
        "    G_y = np.array([[-1,-2,-1], [0,0,0], [1,2,1]]) # Sobel operator on y direction\n",
        "    I_x = signal.convolve2d(img[:,:,0], G_x, mode=\"same\")\n",
        "    I_y = signal.convolve2d(img[:,:,0], G_y, mode=\"same\")\n",
        "    I_xx = scipy.ndimage.gaussian_filter(I_x**2, sigma=1)\n",
        "    I_xy = scipy.ndimage.gaussian_filter(I_y*I_x, sigma=1)\n",
        "    I_yy = scipy.ndimage.gaussian_filter(I_y**2, sigma=1)\n",
        "\n",
        "    determinant = I_xx * I_yy - I_xy ** 2\n",
        "    trace = I_xx + I_yy\n",
        "    harris_response = determinant - k * trace ** 2\n",
        "    return harris_response"
      ],
      "metadata": {
        "id": "-nnNcG_EAGKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_for_corners = np.copy(img)\n",
        "harris_response = HarrisCorner(img)\n",
        "for i, r_response in enumerate(harris_response):\n",
        "    for j, r in enumerate(r_response):\n",
        "        if r > 0:\n",
        "            img_for_corners[i, j] = [255,0,0]"
      ],
      "metadata": {
        "id": "X5evSBtWDW0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_for_corners)"
      ],
      "metadata": {
        "id": "2RNfkSQxFSg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application 2. Denoise an image"
      ],
      "metadata": {
        "id": "_uX-dcZr2pHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_name, _ = urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/timlentse/Add-Salt_Pepper_noise/master/add%20noise%20%20image.png\",\n",
        "    \"pepper_noise.png\")\n",
        "img = plt.imread(f_name)\n",
        "print(img.shape)\n",
        "img = img[:,:,:3]\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "3YJxcIJ60Oqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denoised_img = signal.medfilt(img, kernel_size=3)\n",
        "print(img.shape)\n",
        "plt.imshow(denoised_img)"
      ],
      "metadata": {
        "id": "H4sBatnMHBK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling\n",
        "\n",
        "[Pooling Methods in Deep Neural Networks, a Review](https://arxiv.org/pdf/2009.07485.pdf#:~:text=We%20divided%20pooling%20methods%20into,of%20Interest%20Pooling%20are%20discussed.)\n",
        "\n",
        "- **Average Pooling**: performs down-sampling by dividing the input into rectangular pooling regions and computing the average values of each region.\n",
        "- **Max Pooling**： passes forward the maximum value within a group of $R$ activations. A max-pooling operator can be applied to down-sample the convolutional output bands, thus reducing variability.\n",
        "- **Mixed Pooling**: hybrid approach by combining the average pooling and max pooling.\n",
        "$$\n",
        "s_j = \\lambda \\max_{i\\in R_j} a_i+(1-\\lambda)\\frac{1}{|R_j|}\\sum_{i\\in R_j} a_i\n",
        "$$\n",
        "- **$L_p$ Pooling**: takes a weighted average of inputs.\n",
        "- **Stochastic Pooling**: applies multinomial distribution to pick the value randomly\n",
        "- **Spatial Pyramid Pooling**: partitions the image into\n",
        "divisions from finer to coarser levels and aggregates local features in them.\n",
        "- **Region of Interest Pooling**: mostly used for object detection and segmentation. The ROI pooling layer worked by shifting the processing specific to individual bounding boxes later in the network architecture\n",
        "\n",
        "<table style=\"width:100%; table-layout:fixed;\">\n",
        "    <tr>\n",
        "        <td> <img src=\"https://s2.loli.net/2022/05/25/pSu6D5WyMGYmdaz.png\" width=\"350px\" /> </td>\n",
        "        <td> <img src=\"https://s2.loli.net/2022/05/25/pDJMRy9GKCv2ugZ.png\" width=\"300px\" /> </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "> Check： Up till now, we keep talking about down-pooling. How to do up-pooling?"
      ],
      "metadata": {
        "id": "zJ2f9lowu_34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application 3: Resize an image"
      ],
      "metadata": {
        "id": "yVx_n4no2sPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_pooling(img, kernel_size = 3):\n",
        "    img_resize = np.zeros((img.shape[0] // kernel_size, img.shape[1] // kernel_size))\n",
        "    for i in range(img_resize.shape[0]):\n",
        "        for j in range(img_resize.shape[1]):\n",
        "            img_resize[i,j] = np.max(img[i*3:i*3+3, j*3:j*3+3])\n",
        "    return img_resize"
      ],
      "metadata": {
        "id": "RBkgETL022FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_resize = np.zeros((179,171,3))\n",
        "for i in range(3):\n",
        "    img_resize[:,:,i] = max_pooling(denoised_img[:,:,i])\n",
        "plt.imshow(img_resize)"
      ],
      "metadata": {
        "id": "8amNMoluMCkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch\n",
        "\n",
        "An open source machine learning framework that accelerates the path from research prototyping to production deployment, primarily developed by MetaAI."
      ],
      "metadata": {
        "id": "-p8jj_Ho7MoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "1mXow7-NOnZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data type: Tensors\n",
        "\n",
        "> A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation. <br> The biggest difference between a numpy array and a PyTorch Tensor is that <u>a PyTorch Tensor can run on either CPU or GPU</u>. To run operations on the GPU, just cast the Tensor to a cuda datatype. <br><br> from the *Official Pytorch document*.\n",
        "\n",
        "**You should keep in mind that all the input and output of a pytorch-based network are ```pytorch.Tensor```.**"
      ],
      "metadata": {
        "id": "mwD99YOgdyI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader: Prepare data for training"
      ],
      "metadata": {
        "id": "0bAITkh-FwQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a built-in dataset from Pytorch\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "print(train_data.data.size(), train_data.targets.size())\n",
        "print(test_data.data.size(), test_data.targets.size())"
      ],
      "metadata": {
        "id": "b175BmeXjrvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the labels\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "# Iterate and visualize the dataset\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    img, label = train_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m6Z1DoSNGTS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset\n",
        "# This class has the same functionality as datasets.FashionMINST.\n",
        "# It is only for demonstration. Do not run it.\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, annotations_file, img_dir:str, transform:bool=None, target_transform:bool=None):\n",
        "        \"\"\"Run once when instantiating the Dataset object.\"\"\"\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of samples in our dataset.\"\"\"\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Load and return a sample from the dataset at the given index idx\"\"\"\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "4U1SWzILGnIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FashionMNIST into the DataLoader and iterate through the dataset as needed\n",
        "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "# If you have successfully setup your custom datset, you can run\n",
        "# training_data = CustomImageDataset(**kwargs)\n",
        "# test_data = CustImageDataset(**kwargs)\n",
        "# train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "5Oa9wHXjKVxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a random image and its label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "j2-YjJQNN80B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Structure"
      ],
      "metadata": {
        "id": "f4E_YH5_d40w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Network Components\n",
        "\n",
        "##### Classical layers for a CNN network:\n",
        "\n",
        "- **Convolution layer**: The first layer of a CNN is always a Convolutional Layer. Convolutional layers apply a convolution operation to the input, passing the result to the next layer. A convolution converts all the pixels in its receptive field into a single value.\n",
        "- **Activation layer**: The choice of activation function in the hidden layer will control how well the network model learns the training dataset. The choice of activation function in the output layer will define the type of predictions the model can make.\n",
        "- **Normalization layer**: Layer normalization normalizes input across the features instead of normalizing input features across the batch dimension in batch normalization.\n",
        "- **Pooling layer**: The main purpose of pooling layer is to progressively reduce the spatial size of the input image, so that number of computations in the network are reduced\n",
        "- **Dropout layer**: The dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
        "- **Linear layer**: Linear layers use matrix multiplication to transform their input features into output features using a weight matrix."
      ],
      "metadata": {
        "id": "JFeSjz46er-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Important parameters for the layers:\n",
        "\n",
        "- in_channels (int): number of channels in the input image\n",
        "- out_channels (int): number of channels produced by the convolution\n",
        "- kernel_size (int or tuple): size of the convolving kernel\n",
        "- stride (int or tuple, optional): number of pixels to pass at a time when sliding the convolutional kernel. Default: 1\n",
        "- padding (int or tuple, optional): use zero padding on the border of the image to preserve its size. Default: 0\n",
        "- dilation (int or tuple, optional): space between kernel elements. Default: 1"
      ],
      "metadata": {
        "id": "ohUANX6c9aQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Calculate the output matrix size based on input size and the layer's parameters\n",
        "\n",
        "<img width=\"700px\" src=\"https://s2.loli.net/2022/05/25/JeXZ317hgKNOIF4.png\">\n",
        "\n",
        "<!-- $$\n",
        "H_{\\textrm{out}} = \\left\\lfloor \\frac{H_{\\textrm{in}}+2\\times \\textrm{padding}[0]-\\textrm{dilation}[0]\\times(\\textrm{kernel_size}[0]-1)-1}{\\textrm{stride}[0]} +1 \\right\\rfloor\n",
        "$$\n",
        "$$\n",
        "W_{\\textrm{out}} = \\left\\lfloor \\frac{H_{\\textrm{in}}+2\\times \\textrm{padding}[1]-\\textrm{dilation}[1]\\times(\\textrm{kernel_size}[1]-1)-1}{\\textrm{stride}[1]} +1 \\right\\rfloor\n",
        "$$ -->\n",
        "\n",
        "<table style=\"width:100%; table-layout:fixed;\">\n",
        "    <tr>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/arbitrary_padding_no_strides.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/full_padding_no_strides.gif\"></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>No padding, no strides</td>\n",
        "        <td>Arbitrary padding, no strides</td>\n",
        "        <td>Half padding, no strides</td>\n",
        "        <td>Full padding, no strides</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_strides.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides_odd.gif\"></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>No padding, strides</td>\n",
        "        <td>Padding, strides</td>\n",
        "        <td>Padding, strides (odd)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides_transposed.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/arbitrary_padding_no_strides_transposed.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides_transposed.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/full_padding_no_strides_transposed.gif\"></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>No padding, no strides, <br>transposed</td>\n",
        "        <td>Arbitrary padding, no strides, <br>transposed</td>\n",
        "        <td>Half padding, no strides, <br>transposed</td>\n",
        "        <td>Full padding, no strides, <br>transposed</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_strides_transposed.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides_transposed.gif\"></td>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/padding_strides_odd_transposed.gif\"></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>No padding, strides, <br>transposed</td>\n",
        "        <td>Padding, strides, <br>transposed</td>\n",
        "        <td>Padding, strides, <br>transposed (odd)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><img width=\"150px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/dilation.gif\"></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>No padding, no stride, dilation</td>\n",
        "    </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "TJZJFzGs9kuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Famous CNNs\n",
        "\n",
        "##### VGGNet (2014)\n",
        "\n",
        "<img width=\"100%\" src=\"https://miro.medium.com/max/1400/1*hs8Ud3X2LBzf5XMAFTmGGw.jpeg\">\n",
        "\n",
        "##### U-Net (2015)\n",
        "\n",
        "<img width=\"100%\" src=\"https://nchlis.github.io/2019_10_30/architecture_unetV2.png\">\n",
        "\n",
        "##### ResNet (2015)\n",
        "\n",
        "<img width=\"100%\" src=\"https://lh5.googleusercontent.com/fIXDrntrxU-YJewW148x4VsJICzisvWOj6voUUq0eU2bdxv54e2OWJEIrgyjC4K3c2Y_zHOrpT7AQl5UP-laUEo_U0HXdAtSanORH6JudtCwwGK6oUjhSH8Coj3d2mqovYBhEe0s\n",
        "\">\n",
        "\n",
        "\n",
        "##### Inception v3 （2015）\n",
        "\n",
        "<img width=\"100%\" src=\"https://lh3.googleusercontent.com/bA_Rkj4a0sA3NZ1wjUYIO5_eq0hUmiBNbagOFb84C8Y9GxeedGUYNd-LIbhAlpW-1o8xSeNypMnbD6p-XsrAQvup3FeWXrAoZig7l7Y9WIK3uDHooEMEKiNNQ2qt0PfA4Zfsyltn\n",
        "\">\n",
        "\n"
      ],
      "metadata": {
        "id": "FwyVkRvQ-IY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TypicalCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # batch size is 64\n",
        "        # input size 64 x 1 x 28 x 28\n",
        "        super(TypicalCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1), # 64 x 16 x 26 x 26\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, 1), # 64 x 32 x 24 x 24\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32*24*24, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # flatten the output of conv2 to (64, 32 x 24 x 24)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.out(x)\n",
        "        return output, x"
      ],
      "metadata": {
        "id": "Zqn5KZ-dTXLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = TypicalCNN()\n",
        "print(cnn_model)\n",
        "cnn_model.to(device)"
      ],
      "metadata": {
        "id": "HYPAguHodxQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss"
      ],
      "metadata": {
        "id": "IWx4WwskehzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "print(criterion)"
      ],
      "metadata": {
        "id": "UPuJaSRSd5OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizer"
      ],
      "metadata": {
        "id": "ad1PAtG1ek9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.01)\n",
        "print(optimizer)"
      ],
      "metadata": {
        "id": "4LMT8CBgehfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "6wXhuUVRe5nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, model, data_loader):\n",
        "    model.train()\n",
        "\n",
        "    # train the model\n",
        "    total_step = len(data_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, labels in data_loader:\n",
        "            batch_x = images.to(device)\n",
        "            batch_y = labels.to(device)\n",
        "\n",
        "            output = model(batch_x)[0]\n",
        "            loss = criterion(output, batch_y)\n",
        "            # clear gradients for this training step \n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            \n",
        "        print ('Epoch {}, Loss: {:.4f}'.format(epoch, loss.item()))"
      ],
      "metadata": {
        "id": "KbnQ9U7Md4dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(10, cnn_model, train_dataloader)"
      ],
      "metadata": {
        "id": "J909hPp-gA23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test"
      ],
      "metadata": {
        "id": "uC6ELqIef9bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in data_loader:\n",
        "            batch_x = images.to(device)\n",
        "            batch_y = labels.to(device)\n",
        "\n",
        "            test_output, last_layer = model(batch_x)\n",
        "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
        "            \n",
        "            correct += (pred_y == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "        accuracy = correct / total\n",
        "        print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n"
      ],
      "metadata": {
        "id": "XvoN_U7qf76v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(cnn_model, test_dataloader)"
      ],
      "metadata": {
        "id": "O7RVmdMdsT2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Nf1VnQHi9y0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xHwHkCBIsWbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}